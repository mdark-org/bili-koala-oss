---
title: "[Hacker News 周报] 编译至 Bash 的现代脚本语言；从零开始构建 Llama3；开源内网穿透工具"
description: "了解科技资讯、把握行业脉搏。每周快速浏览 Hacker News 精选。本期 Hacker Newsletter 地址：https://mailchi.mp/hackernewsletter/701"
tags: []
date: 1716696900
bvid: BV1jx4y1n7Vp
---
了解科技资讯，把握行业脉搏，大家好，我是 Koala，欢迎收看第 701 期 Hacker News 周报。

---

### SST｜ 基于 serverless 架构的全栈框架
https://sst.dev/

SST 是一款基于 serverless 架构的全栈框架，SST 的核心理念是让开发者通过简单易用的方式，构建和部署现代化的外应用程序。SST 的亮点主要有以下几个方面，首先，它对前端框架有着出色的支持，例如 Nextjs, Sveltekit, Astro 等都可以无缝集成。其次，SST 提供了丰富的后端服务组件，涵盖了数据库，API 网关，认证等常见需求，通过声明式配置即可快速创建。第三，SST 的环境隔离机制非常人性化，既可以在本地通过 CLI 轻松创建开发，测试等环境，也支持通过 Git 的分支或 pull request 自动生成预览环境，适合不同规模的团队。Koala 认为，最初 SST 围绕 AWS 的 Lambda 服务和其他后端服务设计，但在最近的版本中，SST 将其底层引擎替换为 Terraform 或 Plumi，使其可以对接其他 serverless 供应商，团队也基于新的引擎提供了与 CloudFlare 集成的实力。

---

### Amber｜编译至 Bash 的现代脚本语言
https://amber-lang.com/

Amber 是一种全新的编程语言，它最终会被编译成 Bash 脚本。我们知道传统的 Shell 脚本虽然功能强大，但缺乏现代编程语言的许多优秀特性，比如类型安全，运行时安全检查等，导致编写和维护复杂脚本时容易出错。Amber 的出现正是为了解决这一痛点，它的设计理念是提供一种现代化的语法，允许开发者以更优雅，安全和高效的方式来撰写脚本程序。Amber 保留了常见编程语言的许多语法特性，因此对于有编程经验的人来说上手相对容易。更重要的是，它引入了类型安全的概念，从根源上避免了非类型化语言中的许多麻烦。此外，Amber 还着重于运行时安全性检查，要求开发者明确处理可能发生的各种异常情况。Koala 认为，Amber 是一种面向未来的脚本语言，它将 Bash 脚本的实用性和现代编程语言的安全性，可维护性有机结合，对于那些渴望编写健壮，高效，可维护的脚本程序，同时又习惯于现代语言语法的开发人员来说，Amber 绝对是一个值得关注的项目。

---

### Avvvatars｜ 有趣的 React 头像组件库
https://github.com/nusu/avvvatars

Avvvatars 是一个非常有趣的 React 头像组件库，它提供了 40 种精致的颜色和 60 种独特的形状，让您在项目中随时随地展示个性化的头像。这个库最大的亮点就是高度的可定制性，您不仅可以选择使用文字或图形作为头像，还能自由调整头像的大小，阴影，圆角以及边框细节，打造出独一无二的风格。在实现上，Avvvatars 会根据您输入的字符串，计算出一个唯一的 ID，最终稳定的生成头像，比如输入 Koala 聊开源，不管渲染多少次，得到的头像都将是同一个。

---

### Piko｜ Ngrok 的开源替代品
https://github.com/andydunstall/piko

Piko 是一款开源的 Ngrok 替代品，可以实现将本地开发环境暴露到公网和内网穿透的功能。Piko 支持以集群形式运行，实现故障容错，水平扩展和零停机部署。在设计目标上，Piko 也专注于服务生产流量，支持访问客户网络，构建自代云服务以及连接物联网设备等场景。它构建于 Kubernetes 之上，可作为 stateful site 在负载均衡器或 Kubernetes Gateway 后部署。Koala 认为，Ngrok 等产品无论是在开发测试，还是提升安全性方面都很有价值，但不支持自部署大大限制了其使用场景。Piko 以开源且支持自部署的形式提供，很好的补齐了这一领域的缺失，其设计注重于大规模部署和生产稳定性，也将帮助他们获得更多用户。

---

### Unify｜ 一个 LLM AI 路由
https://unify.ai/

Unify 是一个 LLM AI 路由，一方面它将大部分常用 LLM 模型进行了封装，使客户可以通过统一的 Unify 的接口，访问不同的 LLM 后端。另一方面，它提供了自动选择最优模型的路由功能。在 Unify 的路由模块中，它会综合考虑输出质量，响应速度和成本三个因素，自动将请求路由到在某个场景下表现最优的模型。它利用基于神经网络的评分函数，预测每个模型的质量表现，同时基于最新实时基准数据评估不同区域的延迟和定价，最终让开发者以更低的总成本构建 LLM 应用。

---

### 从零构建 Llama3 的精彩教程
https://github.com/naklecha/llama3-from-scratch

最后是一个详细解释了如何从头实现 Llama3 模型的精彩教程，作者分步骤讲解了 tokenizer, embedding, 注意力机制，前馈网络等关键模块是如何构建和计算的，并通过大量注释和图示帮助读者理解。值得一提的是，作者不仅提供了代码，还分享了自己的动机和愿景，他是一个旨在普及研究，让科研更加贴近大众的开源社区成员，这种基于兴趣和理想的自作付出，也让这个项目更具有意义和趣味性。Koala 认为，整个项目展现了作者对 Transformer 模型原理和编程实现的深入理解，也体现了他把复杂的东西解释清晰的能力，这种从零到一，一步一步构建和讲解的方式，对想要全面掌握大语言模型原理和细节的读者来说，是非常宝贵的学习资源。以上就是本期 Hacker News 周报摘要，谢谢您的收看。

